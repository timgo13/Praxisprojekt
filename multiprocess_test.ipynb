{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movie_archive\\movies_metadata.csv')\n",
    "ratings_small = pd.read_csv('movie_archive\\\\ratings_small.csv')\n",
    "links_small = pd.read_csv('movie_archive\\links_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf = CountVectorizer(analyzer='word', ngram_range=(1, 3), stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['title'].apply(str) + \" \" + movies['overview'].apply(str))\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_list = ratings_small['userId'].unique()\n",
    "movieid_list = movies['id'].to_list()\n",
    "# changes movieId type to int and deletes all false entrys\n",
    "movieid_list = [x for x in movieid_list if x.isdigit()]\n",
    "movieid_list = list(map(int, movieid_list))\n",
    "\n",
    "# get all movie vector rated from user\n",
    "def get_user_rated_movies(ids):\n",
    "   \n",
    "    movie_vector_list = []\n",
    "    for i in ids:\n",
    "        tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == i]\n",
    "        try:\n",
    "            index = movieid_list.index(int(tmdbId))\n",
    "            movie_vector = tfidf_matrix[index]\n",
    "            movie_vector_list.append(movie_vector)\n",
    "        except ValueError:\n",
    "            print (\"ValueError tmdbId: \" + str(tmdbId))     # deleted/NaN movies\n",
    "        \n",
    "    movie_vectors = scipy.sparse.vstack(movie_vector_list)\n",
    "\n",
    "    return movie_vectors \n",
    "\n",
    "# compute all movie vector form specific user into one vector for each user\n",
    "all_user_profiles = {}\n",
    "\n",
    "def create_user_vectors():\n",
    "    for uid in userid_list:\n",
    "        user_profile = ratings_small.loc[ratings_small['userId'] == uid]\n",
    "        user_rated_movies_vector_list = get_user_rated_movies(user_profile['movieId'].to_list())\n",
    "        try:\n",
    "            user_vector = user_rated_movies_vector_list[0]\n",
    "            for x in user_rated_movies_vector_list[1:]:\n",
    "                user_vector = user_vector + x\n",
    "\n",
    "            user_norm = sklearn.preprocessing.normalize(user_vector)\n",
    "            all_user_profiles[uid] = user_norm\n",
    "            print(str(uid) + \" finished\")\n",
    "        except TypeError:\n",
    "            print(str(uid) + \" didnt work, coo matrix parse error\")\n",
    "\n",
    "%time create_user_vectors()"
   ]
  }
 ]
}
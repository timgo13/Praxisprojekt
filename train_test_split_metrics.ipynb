{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd03410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884",
   "display_name": "Python 3.8.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "movies = pd.read_csv('movie_archive\\movies_metadata.csv')\n",
    "ratings_small = pd.read_csv('movie_archive\\\\ratings_small.csv')\n",
    "links_small = pd.read_csv('movie_archive\\links_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train, ratings_test = train_test_split(ratings_small, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "70002\n30002\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings_train))\n",
    "print(len(ratings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<45466x1000000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2536808 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), stop_words='english', max_features= 1000000)\n",
    "tfidf_matrix = tfidf.fit_transform(movies['title'].apply(str) + \" \" + movies['overview'].apply(str))\n",
    "#tfidf_matrix = tfidf.fit_transform(movies['overview'].apply(str))\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   userId  movieId  rating  timestamp  imdbId  tmdbId\n",
       "0     633      587     3.0  848518496   99653   251.0\n",
       "1     388      587     4.0  946523761   99653   251.0\n",
       "2      67      587     3.0  854714282   99653   251.0\n",
       "3     605      587     3.0  980177887   99653   251.0\n",
       "4      30      587     2.0  945277405   99653   251.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>imdbId</th>\n      <th>tmdbId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>633</td>\n      <td>587</td>\n      <td>3.0</td>\n      <td>848518496</td>\n      <td>99653</td>\n      <td>251.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>388</td>\n      <td>587</td>\n      <td>4.0</td>\n      <td>946523761</td>\n      <td>99653</td>\n      <td>251.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>587</td>\n      <td>3.0</td>\n      <td>854714282</td>\n      <td>99653</td>\n      <td>251.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>605</td>\n      <td>587</td>\n      <td>3.0</td>\n      <td>980177887</td>\n      <td>99653</td>\n      <td>251.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30</td>\n      <td>587</td>\n      <td>2.0</td>\n      <td>945277405</td>\n      <td>99653</td>\n      <td>251.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "ratings_train_merge = ratings_train.merge(links_small, on='movieId')\n",
    "ratings_train_merge.head()\n",
    "ratings_test_merge = ratings_test.merge(links_small, on='movieId')\n",
    "ratings_test_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all movie vector form specific user into one vector for each user\n",
    "all_user_profiles = {}\n",
    "count_to_big = 0\n",
    "count_false_int = 0\n",
    "\n",
    "# get all movie vector rated from user\n",
    "def get_user_rated_movies(ids):\n",
    "    \n",
    "        movie_vector_list = []\n",
    "        for i in ids:\n",
    "            tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == i]\n",
    "            try:\n",
    "                index = movieid_list.index(int(tmdbId))\n",
    "                movie_vector = tfidf_matrix[index]\n",
    "                movie_vector_list.append(movie_vector)\n",
    "            except ValueError:\n",
    "                #print (\"ValueError tmdbId: \" + str(tmdbId))     # deleted/NaN movies\n",
    "                count_false_int = count_false_int + 1\n",
    "\n",
    "\n",
    "        movie_vectors = scipy.sparse.vstack(movie_vector_list)\n",
    "\n",
    "        return movie_vectors\n",
    "\n",
    "\n",
    "def create_user_vector_jit(user_rated_movies_vector_array):\n",
    "        \n",
    "        user_vector = user_rated_movies_vector_array.sum(axis=0)\n",
    "\n",
    "        return user_vector\n",
    "\n",
    "\n",
    "def create_user_vectors(uid):\n",
    "        \n",
    "        # --- Train Data ---\n",
    "        user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "            \n",
    "        user_rated_movies_vector_list = get_user_rated_movies(user_profile['movieId'].to_list())\n",
    "        n = user_rated_movies_vector_list.shape[0]\n",
    "\n",
    "        if n > 1500:\n",
    "            count_to_big = count_to_big + 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            user_vectors_array = scipy.sparse.csr_matrix.toarray(user_rated_movies_vector_list)\n",
    "            user_vectors_array.reshape(user_rated_movies_vector_list.shape)\n",
    "\n",
    "            user_vector = create_user_vector_jit(user_vectors_array)\n",
    "\n",
    "            user_norm = sklearn.preprocessing.normalize(scipy.sparse.csr_matrix(user_vector))\n",
    "            all_user_profiles[uid] = user_norm\n",
    "\n",
    "\n",
    "# Sorting Threading\n",
    "recommendation_users = {}\n",
    "\n",
    "def sort_user_vectors(uid):\n",
    "    if uid in all_user_profiles.keys():\n",
    "        user_vec = all_user_profiles[uid]\n",
    "        cosine_similarity_user_movies = cosine_similarity(user_vec, tfidf_matrix)\n",
    "        top_similar = cosine_similarity_user_movies[0].argsort()[:100:-1]\n",
    "        #top_similar = cosine_similarity_user_movies[0].sort(kind='timsort')[:100:-1]\n",
    "        #top_similar = np.sort(cosine_similarity_user_movies[0], kind='stable')\n",
    "        recommendation_users[uid] = [(cosine_similarity_user_movies[0][i], movies['id'][i]) for i in top_similar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time Calculate Vectors HH:MM:SS:  0:02:08.609323\n",
      "Time Sorting HH:MM:SS:  0:02:58.636420\n"
     ]
    }
   ],
   "source": [
    "all_user_profiles = {}\n",
    "count_to_big = 0\n",
    "count_false_int = 0\n",
    "recommendation_users = {}\n",
    "\n",
    "userid_list = ratings_train['userId'].unique()\n",
    "movieid_list = movies['id'].to_list()\n",
    "# changes movieId type to int and deletes all false entrys\n",
    "movieid_list = [x for x in movieid_list if x.isdigit()]\n",
    "movieid_list = list(map(int, movieid_list))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executer:\n",
    "    executer.map(create_user_vectors, userid_list)\n",
    "\n",
    "end = timer()\n",
    "print (\"Time Calculate Vectors HH:MM:SS: \",timedelta(seconds=end-start))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executer:\n",
    "    executer.map(sort_user_vectors, userid_list)\n",
    "\n",
    "end = timer()\n",
    "print (\"Time Sorting HH:MM:SS: \",timedelta(seconds=end-start))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "recommendation_users_top = recommendation_users\n",
    "for k, v in recommendation_users_top.items():\n",
    "    recommendation_users_top[k] = v[:10000]\n",
    "\n",
    "len(recommendation_users_top[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n"
     ]
    }
   ],
   "source": [
    "# Remove movies used to create User Vector\n",
    "\n",
    "percentage_already_seen = []\n",
    "cleaned_recommendations = {}\n",
    "for uid in userid_list:\n",
    "    if uid in all_user_profiles.keys():\n",
    "        user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "        user_recommendation = recommendation_users_top[uid]\n",
    "\n",
    "        user_profile_mid_list = user_profile['movieId'].to_list()\n",
    "        user_tmdb_list = []\n",
    "        for m in user_profile_mid_list:\n",
    "            tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == m]\n",
    "            try:\n",
    "                user_tmdb_list.append(int(tmdbId))\n",
    "            except ValueError:\n",
    "                #print(\"ValueError: \" + str(tmdbId))\n",
    "                count_false_int = count_false_int + 1\n",
    "            \n",
    "        m_count = 0\n",
    "        for cos, mid in user_recommendation:\n",
    "            try:\n",
    "                if int(mid) in user_tmdb_list:\n",
    "                    m_count += 1\n",
    "                    user_recommendation.remove((cos,mid))\n",
    "            except ValueError:\n",
    "                print(\"ValueError: \" + str(mid) + \" not in tmdbid list\")    #Fehler weil, schon gesucht aber nicht gefunden // skipped because to big sample size\n",
    "\n",
    "        cleaned_recommendations[uid] = user_recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 2012-09-29 not in tmdbid list\n",
      "ValueError: 1997-08-20 not in tmdbid list\n",
      "ValueError: 2014-01-01 not in tmdbid list\n",
      "Mean Percentage of good Recommendations (based on Test Split): 0.026179622284996623\n"
     ]
    }
   ],
   "source": [
    "# Calculate Percentage of user rated movies from test split in recommended, top 10/50/100\n",
    "top_value = 100\n",
    "user_percentages = []\n",
    "nan_count = 0\n",
    "for uid in userid_list:\n",
    "    user_profile = ratings_test.loc[ratings_test['userId'] == uid]\n",
    "    found_movies = 0\n",
    "    if uid in recommendation_users.keys():\n",
    "        user_recommendations = cleaned_recommendations[uid]\n",
    "        #print(len(user_recommendations))\n",
    "        #tmdbId_list = user_profile['tmdbId'].to_list():\n",
    "\n",
    "        user_tmdb_list = []\n",
    "        for m in user_profile_mid_list:\n",
    "            tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == m]\n",
    "            try:\n",
    "                user_tmdb_list.append(int(tmdbId))\n",
    "            except ValueError:\n",
    "                #print(\"ValueError: \" + str(tmdbId))\n",
    "                count_false_int = count_false_int + 1\n",
    "\n",
    "        for cos, mid in user_recommendations[:top_value]:\n",
    "            try:\n",
    "                if int(mid) in user_tmdb_list:\n",
    "                    found_movies = found_movies + 1\n",
    "            except ValueError:\n",
    "                print(\"ValueError: \" + str(mid) + \" not in tmdbid list\")\n",
    "\n",
    "       \n",
    "    user_percentages.append(found_movies/len(user_profile))\n",
    "\n",
    "mean_percentage = sum(user_percentages)/len(user_percentages)\n",
    "print(\"Mean Percentage of good Recommendations (based on Test Split): \" + str(mean_percentage))"
   ]
  },
  {
   "source": [
    "# feature size 1mio, title + overview, top100\n",
    "Mean Percentage of good Recommendations (based on Test Split): 0.06530752814292558\n",
    "\n",
    "# feature size 1mio, only overview, top100\n",
    "Mean Percentage of good Recommendations (based on Test Split): 0.022035657968376067"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd03410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884",
   "display_name": "Python 3.8.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import scipy\n",
    "\n",
    "movies = pd.read_csv('movie_archive\\movies_metadata.csv')\n",
    "ratings_small = pd.read_csv('movie_archive\\\\ratings_small.csv')\n",
    "links_small = pd.read_csv('movie_archive\\links_small.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "words = set(nltk.corpus.words.words())\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def remove_non_english(sent):\n",
    "    s = \" \".join(w for w in nltk.wordpunct_tokenize(sent) if w.lower() in words or not w.isalpha())\n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movies.filter(['id','title','overview'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before: 45466\n",
      "After: 37713\n"
     ]
    }
   ],
   "source": [
    "# Create new movies df, with only important columns\n",
    "df = movies.filter(['id','title','overview'], axis=1)\n",
    "print('Before: ' + str(len(df)))\n",
    "df = df.dropna()\n",
    "# check movies ids, convert to int, drop if not possible\n",
    "# check if text in english\n",
    "for id in df['id'].to_list():\n",
    "    try:\n",
    "        id = int(id[0])\n",
    "    except ValueError:\n",
    "        df = df[df['id'] != id]\n",
    "\n",
    "for title in df['title'].to_list():\n",
    "    try:\n",
    "        title = str(title)\n",
    "        if title == 'nan' or title == '' or title == ' ':\n",
    "            df = df[df['title'] != title]\n",
    "        elif len(remove_non_english(title)) < len(title)/4:\n",
    "            df = df[df['title'] != title]\n",
    "    except ValueError:\n",
    "        df = df[df['title'] != title]\n",
    "\n",
    "for overview in df['overview'].to_list():\n",
    "    try:\n",
    "        overview = str(overview)\n",
    "        if overview == 'nan' or overview == '' or overview == ' ' or overview == '...':\n",
    "            df = df[df['overview'] != overview]\n",
    "        elif len(remove_non_english(overview)) < len(overview)/2:\n",
    "            df = df[df['overview'] != overview]\n",
    "    except ValueError:\n",
    "        df = df[df['overview'] != overview]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print('After: ' + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 37713 entries, 0 to 37712\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   id        37713 non-null  object\n 1   title     37713 non-null  object\n 2   overview  37713 non-null  object\ndtypes: object(3)\nmemory usage: 884.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_texts = df['overview'].apply(str).to_list()\n",
    "movie_titles = df['title'].apply(str).to_list()\n",
    "text_tokens = []\n",
    "for i in range(len(movie_texts)):\n",
    "    if movie_titles[i] != 'nan' and movie_texts[i] != 'nan':\n",
    "        text = movie_titles[i] + \" \" + movie_texts[i]\n",
    "        #text = porter.stem(text)\n",
    "        text = remove_stopwords(text)\n",
    "        text_tokens.append(gensim.utils.simple_preprocess(text))\n",
    "\n",
    "tagged_text = [TaggedDocument(t, [i]) for i, t in enumerate(text_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32.25383819902951"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "text_len = []\n",
    "for i in range(len(tagged_text)):\n",
    "    text_len.append(len(tagged_text[i].words))\n",
    "\n",
    "avg_len = sum(text_len) / len(text_len)\n",
    "avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(dm=0, dbow_words=1, min_count=4, negative=3,\n",
    "                hs=0, sample=1e-4, window=10, vector_size=100, workers=8)\n",
    "#model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=3, window=5 ,epochs=10)\n",
    "\n",
    "model.build_vocab(tagged_text)\n",
    "\n",
    "model.train(tagged_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('natured', 0.7135628461837769),\n",
       " ('slob', 0.5717315077781677),\n",
       " ('so', 0.5646793842315674),\n",
       " ('charm', 0.5600972175598145),\n",
       " ('bad', 0.5483207106590271),\n",
       " ('awfully', 0.5448116660118103),\n",
       " ('tuned', 0.5418558716773987),\n",
       " ('sione', 0.5400313138961792),\n",
       " ('doing', 0.536138117313385),\n",
       " ('easygoing', 0.5302959680557251)]"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "80003\n20001\n"
     ]
    }
   ],
   "source": [
    "ratings_train, ratings_test = train_test_split(ratings_small, test_size=0.2)\n",
    "print(len(ratings_train))\n",
    "print(len(ratings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68157\n"
     ]
    }
   ],
   "source": [
    "movieid_list = df['id'].to_list()\n",
    "movieid_list = list(map(int, movieid_list))\n",
    "\n",
    "\n",
    "for r in ratings_train['movieId']:\n",
    "    try:\n",
    "        mid = r\n",
    "        tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == int(mid)]\n",
    "        index = movieid_list.index(int(tmdbId))\n",
    "    except ValueError:\n",
    "        ratings_train = ratings_train[ratings_train['movieId'] != mid]\n",
    "\n",
    "print(len(ratings_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16963\n"
     ]
    }
   ],
   "source": [
    "for r in ratings_test['movieId']:\n",
    "    try:\n",
    "        mid = r\n",
    "        tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == int(mid)]\n",
    "        index = movieid_list.index(int(tmdbId))\n",
    "    except ValueError:\n",
    "        ratings_test = ratings_test[ratings_test['movieId'] != mid]\n",
    "\n",
    "print(len(ratings_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "85120\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings_small\n",
    "for r in ratings['movieId']:\n",
    "    try:\n",
    "        mid = r\n",
    "        tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == int(mid)]\n",
    "        index = movieid_list.index(int(tmdbId))\n",
    "    except ValueError:\n",
    "        ratings = ratings[ratings['movieId'] != mid]\n",
    "\n",
    "print(len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferr_doc_vecs = []\n",
    "for i in range(len(tagged_text)):\n",
    "    inferred_vector = model.infer_vector(tagged_text[0].words, steps=30, alpha=0.025)\n",
    "    inferr_doc_vecs.append(inferred_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all movie vector form specific user into one vector for each user\n",
    "all_user_profiles = {}\n",
    "\n",
    "#userid_list = ratings_train['userId'].unique()\n",
    "userid_list = ratings['userId'].unique()\n",
    "movieid_list = df['id'].to_list()\n",
    "movieid_list = list(map(int, movieid_list))\n",
    "\n",
    "# get all movie vector rated from user\n",
    "def get_user_rated_movies(ids):\n",
    "    \n",
    "        movie_vector_list = []\n",
    "        for i in ids:\n",
    "            tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == i]\n",
    "            try:\n",
    "                index = movieid_list.index(int(tmdbId))\n",
    "                #movie_vector = model.dv[index]\n",
    "                movie_vector = inferr_doc_vecs[index]\n",
    "                movie_vector_list.append(movie_vector)\n",
    "            except ValueError:\n",
    "                print(\"ValueError\")\n",
    "                #pass\n",
    "\n",
    "        movie_vectors = movie_vector_list\n",
    "        return movie_vectors\n",
    "\n",
    "for uid in userid_list:\n",
    "    #user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "    user_profile = ratings.loc[ratings['userId'] == uid]\n",
    "    user_rated_movies_vector_list = get_user_rated_movies(user_profile['movieId'].to_list())\n",
    "    user_rated_movies_vector_array = np.array(user_rated_movies_vector_list)\n",
    "    #user_vector = user_rated_movies_vector_array.sum(axis=0)\n",
    "    user_vector = np.mean(user_rated_movies_vector_array, axis=0)\n",
    "    all_user_profiles[uid] = user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "len(all_user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_rated_movies_bitarray(ids):\n",
    "    \n",
    "        bitarray = np.zeros(len(movieid_list))\n",
    "        for i in ids:\n",
    "            tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == i]\n",
    "            try:\n",
    "                index = movieid_list.index(int(tmdbId))\n",
    "                bitarray[index] = 1\n",
    "            except ValueError:\n",
    "                #print(\"ValueError\")\n",
    "                pass\n",
    "\n",
    "        return bitarray\n",
    "\n",
    "\n",
    "all_user_bitarrays = {}\n",
    "\n",
    "for uid in userid_list:\n",
    "    user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "    user_rated_movies_bitarray = get_user_rated_movies_bitarray(user_profile['movieId'].to_list())\n",
    "    all_user_bitarrays[uid] = user_rated_movies_bitarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(all_user_bitarrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "doc_vecs = model.dv.get_normed_vectors()\n",
    "len(doc_vecs)\n",
    "type(doc_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('doc2vec_vecsize_50_user_profiles.pickle', 'wb') as f:\n",
    "    pickle.dump(all_user_profiles,f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('doc2vec_vecsize_50_doc_vecs.pickle', 'wb') as f:\n",
    "    pickle.dump(model.dv.get_normed_vectors(),f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('doc2vec_vecsize_50_bit_output.pickle', 'wb') as f:\n",
    "    pickle.dump(all_user_bitarrays,f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "\n",
    "# compute all movie vector form specific user into one vector for each user\n",
    "all_user_profiles_test = {}\n",
    "\n",
    "userid_list = ratings_test['userId'].unique()\n",
    "movieid_list = df['id'].to_list()\n",
    "movieid_list = list(map(int, movieid_list))\n",
    "\n",
    "# get all movie vector rated from user\n",
    "def get_user_rated_movies(ids):\n",
    "    \n",
    "        movie_vector_list = []\n",
    "        for i in ids:\n",
    "            tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == i]\n",
    "            try:\n",
    "                index = movieid_list.index(int(tmdbId))\n",
    "                movie_vector = model.dv[index]\n",
    "                movie_vector_list.append(movie_vector)\n",
    "            except ValueError:\n",
    "                #print(\"ValueError\")\n",
    "                pass\n",
    "\n",
    "        movie_vectors = movie_vector_list\n",
    "        return movie_vectors\n",
    "\n",
    "for uid in userid_list:\n",
    "    user_profile = ratings_test.loc[ratings_test['userId'] == uid]\n",
    "    user_rated_movies_vector_list = get_user_rated_movies(user_profile['movieId'].to_list())\n",
    "    user_rated_movies_vector_array = np.array(user_rated_movies_vector_list)\n",
    "    #user_vector = user_rated_movies_vector_array.sum(axis=0)\n",
    "    user_vector = np.mean(user_rated_movies_vector_array, axis=0)\n",
    "    all_user_profiles[uid] = user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "\n",
    "def get_user_rated_movies_bitarray(ids):\n",
    "    \n",
    "        bitarray = np.zeros(len(movieid_list))\n",
    "        for i in ids:\n",
    "            tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == i]\n",
    "            try:\n",
    "                index = movieid_list.index(int(tmdbId))\n",
    "                bitarray[index] = 1\n",
    "            except ValueError:\n",
    "                #print(\"ValueError\")\n",
    "                pass\n",
    "\n",
    "        return bitarray\n",
    "\n",
    "\n",
    "all_user_bitarrays = {}\n",
    "\n",
    "for uid in userid_list:\n",
    "    user_profile = ratings_test.loc[ratings_test['userId'] == uid]\n",
    "    user_rated_movies_bitarray = get_user_rated_movies_bitarray(user_profile['movieId'].to_list())\n",
    "    all_user_bitarrays[uid] = user_rated_movies_bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('doc2vec_vecsize_50_user_profiles_test.pickle', 'wb') as f:\n",
    "    pickle.dump(all_user_profiles_test,f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('doc2vec_vecsize_50_bit_output_test.pickle', 'wb') as f:\n",
    "    pickle.dump(all_user_bitarrays,f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "recommendation_users = {}\n",
    "for uid in userid_list:\n",
    "    if uid in all_user_profiles.keys():\n",
    "        sims = model.dv.most_similar([all_user_profiles[uid]], topn=len(model.dv))\n",
    "        recommendation_users[uid] = sims\n",
    "len(recommendation_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 of 15 in first recommended already seen\n",
      "0 of 43 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "3 of 139 in first recommended already seen\n",
      "2 of 69 in first recommended already seen\n",
      "1 of 35 in first recommended already seen\n",
      "2 of 60 in first recommended already seen\n",
      "1 of 78 in first recommended already seen\n",
      "1 of 27 in first recommended already seen\n",
      "0 of 40 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "0 of 43 in first recommended already seen\n",
      "4 of 33 in first recommended already seen\n",
      "1 of 19 in first recommended already seen\n",
      "38 of 1154 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "1 of 245 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "2 of 277 in first recommended already seen\n",
      "1 of 69 in first recommended already seen\n",
      "1 of 109 in first recommended already seen\n",
      "2 of 149 in first recommended already seen\n",
      "8 of 465 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "1 of 123 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 29 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "17 of 702 in first recommended already seen\n",
      "0 of 45 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "1 of 103 in first recommended already seen\n",
      "0 of 122 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "0 of 68 in first recommended already seen\n",
      "1 of 24 in first recommended already seen\n",
      "0 of 72 in first recommended already seen\n",
      "0 of 39 in first recommended already seen\n",
      "0 of 29 in first recommended already seen\n",
      "1 of 126 in first recommended already seen\n",
      "0 of 54 in first recommended already seen\n",
      "3 of 74 in first recommended already seen\n",
      "1 of 21 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "1 of 23 in first recommended already seen\n",
      "1 of 24 in first recommended already seen\n",
      "6 of 328 in first recommended already seen\n",
      "0 of 69 in first recommended already seen\n",
      "0 of 30 in first recommended already seen\n",
      "0 of 27 in first recommended already seen\n",
      "0 of 49 in first recommended already seen\n",
      "1 of 30 in first recommended already seen\n",
      "1 of 35 in first recommended already seen\n",
      "1 of 30 in first recommended already seen\n",
      "10 of 362 in first recommended already seen\n",
      "2 of 149 in first recommended already seen\n",
      "0 of 52 in first recommended already seen\n",
      "0 of 56 in first recommended already seen\n",
      "0 of 42 in first recommended already seen\n",
      "3 of 103 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "2 of 72 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 35 in first recommended already seen\n",
      "1 of 67 in first recommended already seen\n",
      "1 of 83 in first recommended already seen\n",
      "3 of 58 in first recommended already seen\n",
      "0 of 57 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "3 of 124 in first recommended already seen\n",
      "36 of 1102 in first recommended already seen\n",
      "0 of 35 in first recommended already seen\n",
      "2 of 102 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "2 of 216 in first recommended already seen\n",
      "2 of 197 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 107 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "5 of 103 in first recommended already seen\n",
      "1 of 80 in first recommended already seen\n",
      "0 of 73 in first recommended already seen\n",
      "2 of 114 in first recommended already seen\n",
      "1 of 21 in first recommended already seen\n",
      "2 of 168 in first recommended already seen\n",
      "1 of 50 in first recommended already seen\n",
      "1 of 35 in first recommended already seen\n",
      "4 of 97 in first recommended already seen\n",
      "1 of 79 in first recommended already seen\n",
      "5 of 110 in first recommended already seen\n",
      "2 of 126 in first recommended already seen\n",
      "2 of 195 in first recommended already seen\n",
      "0 of 50 in first recommended already seen\n",
      "2 of 89 in first recommended already seen\n",
      "0 of 48 in first recommended already seen\n",
      "0 of 125 in first recommended already seen\n",
      "1 of 19 in first recommended already seen\n",
      "0 of 35 in first recommended already seen\n",
      "11 of 461 in first recommended already seen\n",
      "0 of 68 in first recommended already seen\n",
      "0 of 61 in first recommended already seen\n",
      "5 of 358 in first recommended already seen\n",
      "2 of 28 in first recommended already seen\n",
      "0 of 23 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "0 of 80 in first recommended already seen\n",
      "2 of 233 in first recommended already seen\n",
      "1 of 16 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "0 of 31 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 42 in first recommended already seen\n",
      "1 of 133 in first recommended already seen\n",
      "9 of 442 in first recommended already seen\n",
      "3 of 97 in first recommended already seen\n",
      "1 of 54 in first recommended already seen\n",
      "0 of 24 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "2 of 56 in first recommended already seen\n",
      "3 of 136 in first recommended already seen\n",
      "1 of 39 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "3 of 236 in first recommended already seen\n",
      "0 of 24 in first recommended already seen\n",
      "4 of 257 in first recommended already seen\n",
      "0 of 30 in first recommended already seen\n",
      "1 of 61 in first recommended already seen\n",
      "1 of 128 in first recommended already seen\n",
      "6 of 212 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "2 of 29 in first recommended already seen\n",
      "1 of 58 in first recommended already seen\n",
      "2 of 58 in first recommended already seen\n",
      "1 of 48 in first recommended already seen\n",
      "0 of 34 in first recommended already seen\n",
      "0 of 24 in first recommended already seen\n",
      "2 of 41 in first recommended already seen\n",
      "0 of 54 in first recommended already seen\n",
      "0 of 25 in first recommended already seen\n",
      "0 of 23 in first recommended already seen\n",
      "2 of 50 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "0 of 90 in first recommended already seen\n",
      "3 of 158 in first recommended already seen\n",
      "6 of 298 in first recommended already seen\n",
      "0 of 41 in first recommended already seen\n",
      "3 of 149 in first recommended already seen\n",
      "0 of 33 in first recommended already seen\n",
      "1 of 16 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "3 of 217 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "1 of 105 in first recommended already seen\n",
      "2 of 68 in first recommended already seen\n",
      "0 of 56 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "3 of 57 in first recommended already seen\n",
      "1 of 49 in first recommended already seen\n",
      "6 of 322 in first recommended already seen\n",
      "1 of 36 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "1 of 84 in first recommended already seen\n",
      "3 of 73 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "1 of 27 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "1 of 84 in first recommended already seen\n",
      "2 of 170 in first recommended already seen\n",
      "1 of 155 in first recommended already seen\n",
      "2 of 91 in first recommended already seen\n",
      "2 of 29 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 22 in first recommended already seen\n",
      "0 of 87 in first recommended already seen\n",
      "0 of 31 in first recommended already seen\n",
      "1 of 33 in first recommended already seen\n",
      "2 of 143 in first recommended already seen\n",
      "0 of 33 in first recommended already seen\n",
      "5 of 225 in first recommended already seen\n",
      "0 of 59 in first recommended already seen\n",
      "1 of 124 in first recommended already seen\n",
      "1 of 41 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 29 in first recommended already seen\n",
      "3 of 49 in first recommended already seen\n",
      "0 of 31 in first recommended already seen\n",
      "6 of 339 in first recommended already seen\n",
      "0 of 77 in first recommended already seen\n",
      "0 of 47 in first recommended already seen\n",
      "0 of 47 in first recommended already seen\n",
      "2 of 279 in first recommended already seen\n",
      "4 of 165 in first recommended already seen\n",
      "2 of 83 in first recommended already seen\n",
      "1 of 60 in first recommended already seen\n",
      "0 of 27 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "3 of 134 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "0 of 32 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "1 of 24 in first recommended already seen\n",
      "0 of 33 in first recommended already seen\n",
      "20 of 586 in first recommended already seen\n",
      "12 of 597 in first recommended already seen\n",
      "2 of 153 in first recommended already seen\n",
      "1 of 40 in first recommended already seen\n",
      "1 of 59 in first recommended already seen\n",
      "1 of 66 in first recommended already seen\n",
      "1 of 28 in first recommended already seen\n",
      "3 of 99 in first recommended already seen\n",
      "1 of 199 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "0 of 62 in first recommended already seen\n",
      "0 of 25 in first recommended already seen\n",
      "1 of 60 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 24 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "0 of 22 in first recommended already seen\n",
      "0 of 69 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "12 of 458 in first recommended already seen\n",
      "0 of 27 in first recommended already seen\n",
      "0 of 84 in first recommended already seen\n",
      "1 of 105 in first recommended already seen\n",
      "0 of 146 in first recommended already seen\n",
      "1 of 32 in first recommended already seen\n",
      "0 of 62 in first recommended already seen\n",
      "7 of 203 in first recommended already seen\n",
      "2 of 158 in first recommended already seen\n",
      "1 of 40 in first recommended already seen\n",
      "6 of 279 in first recommended already seen\n",
      "1 of 193 in first recommended already seen\n",
      "1 of 44 in first recommended already seen\n",
      "0 of 90 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "4 of 188 in first recommended already seen\n",
      "1 of 71 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "1 of 106 in first recommended already seen\n",
      "0 of 80 in first recommended already seen\n",
      "1 of 24 in first recommended already seen\n",
      "1 of 142 in first recommended already seen\n",
      "0 of 92 in first recommended already seen\n",
      "0 of 99 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "1 of 67 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "2 of 32 in first recommended already seen\n",
      "7 of 443 in first recommended already seen\n",
      "2 of 83 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "2 of 128 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "0 of 27 in first recommended already seen\n",
      "9 of 273 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "0 of 145 in first recommended already seen\n",
      "2 of 51 in first recommended already seen\n",
      "1 of 29 in first recommended already seen\n",
      "1 of 61 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "5 of 148 in first recommended already seen\n",
      "0 of 10 in first recommended already seen\n",
      "0 of 42 in first recommended already seen\n",
      "0 of 33 in first recommended already seen\n",
      "0 of 36 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "1 of 52 in first recommended already seen\n",
      "3 of 90 in first recommended already seen\n",
      "2 of 130 in first recommended already seen\n",
      "1 of 36 in first recommended already seen\n",
      "5 of 274 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "3 of 167 in first recommended already seen\n",
      "0 of 42 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 46 in first recommended already seen\n",
      "0 of 57 in first recommended already seen\n",
      "2 of 192 in first recommended already seen\n",
      "3 of 48 in first recommended already seen\n",
      "23 of 634 in first recommended already seen\n",
      "1 of 163 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "1 of 82 in first recommended already seen\n",
      "0 of 46 in first recommended already seen\n",
      "2 of 255 in first recommended already seen\n",
      "0 of 25 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "2 of 162 in first recommended already seen\n",
      "0 of 67 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "11 of 435 in first recommended already seen\n",
      "0 of 48 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "1 of 85 in first recommended already seen\n",
      "0 of 10 in first recommended already seen\n",
      "18 of 702 in first recommended already seen\n",
      "1 of 204 in first recommended already seen\n",
      "5 of 202 in first recommended already seen\n",
      "1 of 25 in first recommended already seen\n",
      "1 of 40 in first recommended already seen\n",
      "1 of 98 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "1 of 33 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "2 of 51 in first recommended already seen\n",
      "0 of 33 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "2 of 93 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 44 in first recommended already seen\n",
      "5 of 114 in first recommended already seen\n",
      "1 of 17 in first recommended already seen\n",
      "0 of 69 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 24 in first recommended already seen\n",
      "3 of 56 in first recommended already seen\n",
      "1 of 24 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "1 of 19 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 34 in first recommended already seen\n",
      "1 of 78 in first recommended already seen\n",
      "0 of 30 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "2 of 121 in first recommended already seen\n",
      "1 of 22 in first recommended already seen\n",
      "2 of 116 in first recommended already seen\n",
      "6 of 144 in first recommended already seen\n",
      "2 of 223 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "2 of 116 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "1 of 54 in first recommended already seen\n",
      "5 of 356 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "3 of 220 in first recommended already seen\n",
      "0 of 11 in first recommended already seen\n",
      "1 of 19 in first recommended already seen\n",
      "14 of 424 in first recommended already seen\n",
      "0 of 31 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "1 of 48 in first recommended already seen\n",
      "1 of 81 in first recommended already seen\n",
      "2 of 131 in first recommended already seen\n",
      "1 of 26 in first recommended already seen\n",
      "1 of 52 in first recommended already seen\n",
      "0 of 22 in first recommended already seen\n",
      "2 of 157 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 30 in first recommended already seen\n",
      "0 of 71 in first recommended already seen\n",
      "1 of 118 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "4 of 148 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "0 of 39 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 91 in first recommended already seen\n",
      "1 of 50 in first recommended already seen\n",
      "28 of 714 in first recommended already seen\n",
      "2 of 82 in first recommended already seen\n",
      "3 of 222 in first recommended already seen\n",
      "0 of 43 in first recommended already seen\n",
      "6 of 348 in first recommended already seen\n",
      "0 of 63 in first recommended already seen\n",
      "2 of 86 in first recommended already seen\n",
      "6 of 197 in first recommended already seen\n",
      "14 of 540 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "2 of 103 in first recommended already seen\n",
      "0 of 79 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "0 of 33 in first recommended already seen\n",
      "3 of 146 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "1 of 98 in first recommended already seen\n",
      "0 of 30 in first recommended already seen\n",
      "0 of 37 in first recommended already seen\n",
      "0 of 10 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "2 of 48 in first recommended already seen\n",
      "4 of 215 in first recommended already seen\n",
      "1 of 18 in first recommended already seen\n",
      "0 of 29 in first recommended already seen\n",
      "3 of 293 in first recommended already seen\n",
      "2 of 49 in first recommended already seen\n",
      "1 of 206 in first recommended already seen\n",
      "3 of 152 in first recommended already seen\n",
      "1 of 31 in first recommended already seen\n",
      "1 of 20 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "1 of 150 in first recommended already seen\n",
      "0 of 19 in first recommended already seen\n",
      "0 of 49 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "0 of 71 in first recommended already seen\n",
      "3 of 98 in first recommended already seen\n",
      "1 of 113 in first recommended already seen\n",
      "2 of 30 in first recommended already seen\n",
      "1 of 66 in first recommended already seen\n",
      "1 of 31 in first recommended already seen\n",
      "2 of 58 in first recommended already seen\n",
      "1 of 232 in first recommended already seen\n",
      "0 of 23 in first recommended already seen\n",
      "2 of 38 in first recommended already seen\n",
      "5 of 187 in first recommended already seen\n",
      "1 of 206 in first recommended already seen\n",
      "2 of 111 in first recommended already seen\n",
      "0 of 22 in first recommended already seen\n",
      "3 of 222 in first recommended already seen\n",
      "4 of 189 in first recommended already seen\n",
      "1 of 48 in first recommended already seen\n",
      "5 of 127 in first recommended already seen\n",
      "3 of 143 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 42 in first recommended already seen\n",
      "1 of 15 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "4 of 184 in first recommended already seen\n",
      "1 of 25 in first recommended already seen\n",
      "1 of 83 in first recommended already seen\n",
      "3 of 153 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "1 of 58 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "0 of 19 in first recommended already seen\n",
      "0 of 80 in first recommended already seen\n",
      "1 of 38 in first recommended already seen\n",
      "33 of 943 in first recommended already seen\n",
      "0 of 63 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "1 of 25 in first recommended already seen\n",
      "1 of 41 in first recommended already seen\n",
      "14 of 490 in first recommended already seen\n",
      "2 of 57 in first recommended already seen\n",
      "1 of 15 in first recommended already seen\n",
      "6 of 181 in first recommended already seen\n",
      "10 of 472 in first recommended already seen\n",
      "0 of 34 in first recommended already seen\n",
      "7 of 328 in first recommended already seen\n",
      "0 of 19 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "3 of 130 in first recommended already seen\n",
      "0 of 44 in first recommended already seen\n",
      "27 of 862 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "0 of 49 in first recommended already seen\n",
      "3 of 154 in first recommended already seen\n",
      "12 of 560 in first recommended already seen\n",
      "0 of 52 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "13 of 454 in first recommended already seen\n",
      "0 of 34 in first recommended already seen\n",
      "0 of 13 in first recommended already seen\n",
      "1 of 54 in first recommended already seen\n",
      "1 of 67 in first recommended already seen\n",
      "3 of 258 in first recommended already seen\n",
      "4 of 300 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "0 of 91 in first recommended already seen\n",
      "1 of 11 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "5 of 97 in first recommended already seen\n",
      "0 of 103 in first recommended already seen\n",
      "0 of 37 in first recommended already seen\n",
      "1 of 16 in first recommended already seen\n",
      "1 of 15 in first recommended already seen\n",
      "0 of 44 in first recommended already seen\n",
      "0 of 47 in first recommended already seen\n",
      "3 of 81 in first recommended already seen\n",
      "0 of 54 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 86 in first recommended already seen\n",
      "1 of 71 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "0 of 23 in first recommended already seen\n",
      "2 of 167 in first recommended already seen\n",
      "2 of 133 in first recommended already seen\n",
      "0 of 81 in first recommended already seen\n",
      "2 of 30 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "2 of 276 in first recommended already seen\n",
      "1 of 9 in first recommended already seen\n",
      "1 of 31 in first recommended already seen\n",
      "0 of 36 in first recommended already seen\n",
      "12 of 621 in first recommended already seen\n",
      "1 of 114 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 19 in first recommended already seen\n",
      "0 of 11 in first recommended already seen\n",
      "4 of 250 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "0 of 108 in first recommended already seen\n",
      "0 of 25 in first recommended already seen\n",
      "11 of 482 in first recommended already seen\n",
      "2 of 105 in first recommended already seen\n",
      "1 of 108 in first recommended already seen\n",
      "0 of 36 in first recommended already seen\n",
      "2 of 161 in first recommended already seen\n",
      "0 of 92 in first recommended already seen\n",
      "0 of 46 in first recommended already seen\n",
      "2 of 92 in first recommended already seen\n",
      "1 of 19 in first recommended already seen\n",
      "0 of 100 in first recommended already seen\n",
      "0 of 93 in first recommended already seen\n",
      "5 of 407 in first recommended already seen\n",
      "1 of 56 in first recommended already seen\n",
      "2 of 86 in first recommended already seen\n",
      "0 of 36 in first recommended already seen\n",
      "2 of 122 in first recommended already seen\n",
      "1 of 208 in first recommended already seen\n",
      "0 of 44 in first recommended already seen\n",
      "0 of 66 in first recommended already seen\n",
      "6 of 211 in first recommended already seen\n",
      "1 of 15 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 11 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "2 of 46 in first recommended already seen\n",
      "1 of 30 in first recommended already seen\n",
      "1 of 187 in first recommended already seen\n",
      "1 of 66 in first recommended already seen\n",
      "0 of 41 in first recommended already seen\n",
      "104 of 1649 in first recommended already seen\n",
      "0 of 88 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 89 in first recommended already seen\n",
      "0 of 51 in first recommended already seen\n",
      "0 of 25 in first recommended already seen\n",
      "1 of 155 in first recommended already seen\n",
      "0 of 47 in first recommended already seen\n",
      "0 of 46 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "1 of 44 in first recommended already seen\n",
      "0 of 139 in first recommended already seen\n",
      "2 of 92 in first recommended already seen\n",
      "3 of 60 in first recommended already seen\n",
      "6 of 206 in first recommended already seen\n",
      "3 of 174 in first recommended already seen\n",
      "0 of 108 in first recommended already seen\n",
      "61 of 1302 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 28 in first recommended already seen\n",
      "1 of 23 in first recommended already seen\n",
      "0 of 60 in first recommended already seen\n",
      "0 of 87 in first recommended already seen\n",
      "0 of 37 in first recommended already seen\n",
      "0 of 73 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "6 of 245 in first recommended already seen\n",
      "12 of 383 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "3 of 187 in first recommended already seen\n",
      "0 of 27 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "12 of 623 in first recommended already seen\n",
      "1 of 34 in first recommended already seen\n",
      "0 of 86 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "2 of 137 in first recommended already seen\n",
      "5 of 208 in first recommended already seen\n",
      "1 of 42 in first recommended already seen\n",
      "6 of 355 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "0 of 29 in first recommended already seen\n",
      "0 of 59 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "1 of 99 in first recommended already seen\n",
      "0 of 51 in first recommended already seen\n",
      "1 of 55 in first recommended already seen\n",
      "2 of 105 in first recommended already seen\n",
      "5 of 334 in first recommended already seen\n",
      "4 of 147 in first recommended already seen\n",
      "7 of 230 in first recommended already seen\n",
      "2 of 140 in first recommended already seen\n",
      "0 of 19 in first recommended already seen\n",
      "0 of 27 in first recommended already seen\n",
      "0 of 80 in first recommended already seen\n",
      "1 of 67 in first recommended already seen\n",
      "0 of 11 in first recommended already seen\n",
      "8 of 291 in first recommended already seen\n",
      "0 of 42 in first recommended already seen\n",
      "7 of 284 in first recommended already seen\n",
      "2 of 201 in first recommended already seen\n",
      "0 of 99 in first recommended already seen\n",
      "0 of 57 in first recommended already seen\n",
      "0 of 21 in first recommended already seen\n",
      "0 of 43 in first recommended already seen\n",
      "0 of 38 in first recommended already seen\n",
      "0 of 70 in first recommended already seen\n",
      "3 of 263 in first recommended already seen\n",
      "0 of 22 in first recommended already seen\n",
      "0 of 53 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "0 of 29 in first recommended already seen\n",
      "2 of 131 in first recommended already seen\n",
      "1 of 66 in first recommended already seen\n",
      "0 of 22 in first recommended already seen\n",
      "2 of 68 in first recommended already seen\n",
      "52 of 1166 in first recommended already seen\n",
      "0 of 46 in first recommended already seen\n",
      "2 of 106 in first recommended already seen\n",
      "0 of 131 in first recommended already seen\n",
      "0 of 67 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 17 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "0 of 25 in first recommended already seen\n",
      "0 of 19 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "0 of 16 in first recommended already seen\n",
      "1 of 19 in first recommended already seen\n",
      "0 of 15 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "0 of 35 in first recommended already seen\n",
      "0 of 33 in first recommended already seen\n",
      "1 of 101 in first recommended already seen\n",
      "0 of 30 in first recommended already seen\n",
      "0 of 18 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "3 of 102 in first recommended already seen\n",
      "0 of 103 in first recommended already seen\n",
      "1 of 177 in first recommended already seen\n",
      "1 of 58 in first recommended already seen\n",
      "0 of 23 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "6 of 193 in first recommended already seen\n",
      "1 of 29 in first recommended already seen\n",
      "11 of 424 in first recommended already seen\n",
      "1 of 72 in first recommended already seen\n",
      "1 of 90 in first recommended already seen\n",
      "0 of 14 in first recommended already seen\n",
      "1 of 39 in first recommended already seen\n",
      "1 of 94 in first recommended already seen\n",
      "0 of 58 in first recommended already seen\n",
      "0 of 20 in first recommended already seen\n",
      "0 of 34 in first recommended already seen\n",
      "1 of 21 in first recommended already seen\n",
      "7 of 364 in first recommended already seen\n",
      "4 of 306 in first recommended already seen\n",
      "0 of 26 in first recommended already seen\n",
      "0 of 47 in first recommended already seen\n",
      "0 of 12 in first recommended already seen\n",
      "0 of 24 in first recommended already seen\n",
      "0 of 19 in first recommended already seen\n",
      "2 of 80 in first recommended already seen\n",
      "Average Percentage of already seen movies: 0.013151572857873968\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "percentage_already_seen = []\n",
    "for uid in userid_list:\n",
    "    user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "    user_recommendation = recommendation_users[uid]\n",
    "\n",
    "    user_profile_mid_list = user_profile['movieId'].to_list()\n",
    "    user_m_index_list = []\n",
    "    for m in user_profile_mid_list:\n",
    "        tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == m]\n",
    "        try:\n",
    "            index = movieid_list.index(int(tmdbId))\n",
    "            user_m_index_list.append(index)\n",
    "        except ValueError:\n",
    "            #print(\"ValueError: \" + str(m))\n",
    "            pass\n",
    "    \n",
    "    m_count = 0\n",
    "    for m_i, cos in user_recommendation[:len(user_profile)]:\n",
    "        try:\n",
    "            if int(m_i) in user_m_index_list:\n",
    "                m_count += 1\n",
    "        except ValueError:\n",
    "            #print(\"ValueError: \" + str(m_i) + \" not in tmdbid list\") \n",
    "            pass  \n",
    "\n",
    "    if m_count == len(user_profile):\n",
    "        print(str(uid) + \" : the first movies are already viewed\")\n",
    "    else:\n",
    "        print(str(m_count) + \" of \" + str(len(user_profile)) + \" in first recommended already seen\")\n",
    "\n",
    "    p = m_count/len(user_profile)\n",
    "    percentage_already_seen.append(p)\n",
    "\n",
    "average_percentage = sum(percentage_already_seen) / len(percentage_already_seen)\n",
    "print(\"Average Percentage of already seen movies: \" + str(average_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# Average Rank of Movies -> User Vector\n",
    "\n",
    "def compute_avg_rank(uid):\n",
    "    user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "    user_recommendation = recommendation_users[uid]\n",
    "\n",
    "    user_profile_mid_list = user_profile['movieId'].to_list()\n",
    "    user_m_index_list = []\n",
    "    for m in user_profile_mid_list:\n",
    "        tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == m]\n",
    "        try:\n",
    "            index = movieid_list.index(int(tmdbId))\n",
    "            user_m_index_list.append(index)\n",
    "        except ValueError:\n",
    "            #print(\"ValueError: \" + str(m))\n",
    "            pass\n",
    "    \n",
    "    rank_list = []\n",
    "    for mid in user_m_index_list:\n",
    "        rank = 0\n",
    "        for m_i, cos in user_recommendation:\n",
    "            try:\n",
    "                if int(m_i) == int(mid):\n",
    "                    break\n",
    "                rank = rank + 1\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        rank_list.append(rank)   \n",
    "    \n",
    "\n",
    "    r = sum(rank_list)/len(user_profile)\n",
    "    avg_ranks.append(r)\n",
    "    #print(\"UserId: \" + str(uid) + \"Avg_Rank: \" + str(r) + \"User_Len: \" + str(len(user_profile)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time Calculate Vectors HH:MM:SS:  0:09:05.243834\nMax Rank = 37713\nAverage Rank of already seen movies: 19928.398176487823\n"
     ]
    }
   ],
   "source": [
    "avg_ranks = []\n",
    "\n",
    "start = timer()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executer:\n",
    "    executer.map(compute_avg_rank, userid_list)\n",
    "\n",
    "end = timer()\n",
    "print (\"Time Calculate Vectors HH:MM:SS: \",timedelta(seconds=end-start))\n",
    "\n",
    "print(\"Max Rank = \" + str(len(df)))\n",
    "average_percentage = sum(avg_ranks) / len(avg_ranks)\n",
    "print(\"Average Rank of already seen movies: \" + str(average_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove movies used to create User Vector\n",
    "\n",
    "percentage_already_seen = []\n",
    "cleaned_recommendations = {}\n",
    "for uid in userid_list:\n",
    "    \n",
    "    user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "    user_recommendation = recommendation_users[uid]\n",
    "    user_profile_mid_list = user_profile['movieId'].to_list()\n",
    "    user_m_index_list = []\n",
    "    for m in user_profile_mid_list:\n",
    "        tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == m]\n",
    "        try:\n",
    "            index = movieid_list.index(int(tmdbId))\n",
    "            user_m_index_list.append(index)\n",
    "        except ValueError:\n",
    "            pass\n",
    "            \n",
    "    m_count = 0\n",
    "    for m_i, cos in user_recommendation:\n",
    "        try:\n",
    "            if int(m_i) in user_m_index_list:\n",
    "                m_count += 1\n",
    "                user_recommendation.remove((m_i,cos))\n",
    "        except ValueError:\n",
    "            pass  \n",
    "\n",
    "    cleaned_recommendations[uid] = user_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 of 33 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 56 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 194 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 29 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "1 of 213 found in topn= 100\n",
      "2 of 406 found in topn= 100\n",
      "0 of 111 found in topn= 100\n",
      "0 of 97 found in topn= 100\n",
      "0 of 54 found in topn= 100\n",
      "0 of 83 found in topn= 100\n",
      "0 of 27 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "0 of 164 found in topn= 100\n",
      "1 of 31 found in topn= 100\n",
      "0 of 55 found in topn= 100\n",
      "0 of 29 found in topn= 100\n",
      "1 of 93 found in topn= 100\n",
      "2 of 311 found in topn= 100\n",
      "0 of 41 found in topn= 100\n",
      "0 of 36 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "1 of 41 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 33 found in topn= 100\n",
      "0 of 42 found in topn= 100\n",
      "0 of 28 found in topn= 100\n",
      "0 of 90 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 42 found in topn= 100\n",
      "0 of 60 found in topn= 100\n",
      "0 of 17 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "1 of 293 found in topn= 100\n",
      "0 of 117 found in topn= 100\n",
      "0 of 93 found in topn= 100\n",
      "1 of 68 found in topn= 100\n",
      "2 of 70 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 88 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "2 of 84 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 290 found in topn= 100\n",
      "0 of 55 found in topn= 100\n",
      "0 of 31 found in topn= 100\n",
      "0 of 113 found in topn= 100\n",
      "2 of 36 found in topn= 100\n",
      "0 of 67 found in topn= 100\n",
      "0 of 34 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 143 found in topn= 100\n",
      "0 of 73 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "1 of 36 found in topn= 100\n",
      "0 of 45 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 30 found in topn= 100\n",
      "0 of 88 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 27 found in topn= 100\n",
      "0 of 127 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "1 of 59 found in topn= 100\n",
      "0 of 72 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "1 of 164 found in topn= 100\n",
      "0 of 162 found in topn= 100\n",
      "0 of 48 found in topn= 100\n",
      "0 of 28 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 78 found in topn= 100\n",
      "0 of 45 found in topn= 100\n",
      "0 of 41 found in topn= 100\n",
      "0 of 73 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 47 found in topn= 100\n",
      "0 of 57 found in topn= 100\n",
      "0 of 27 found in topn= 100\n",
      "0 of 37 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 49 found in topn= 100\n",
      "0 of 142 found in topn= 100\n",
      "1 of 90 found in topn= 100\n",
      "0 of 48 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 118 found in topn= 100\n",
      "1 of 98 found in topn= 100\n",
      "0 of 76 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 28 found in topn= 100\n",
      "0 of 41 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "1 of 13 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "1 of 13 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 63 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 58 found in topn= 100\n",
      "1 of 147 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 22 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 59 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "2 of 96 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "1 of 171 found in topn= 100\n",
      "0 of 45 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 88 found in topn= 100\n",
      "2 of 271 found in topn= 100\n",
      "0 of 53 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 181 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 44 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "1 of 114 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 25 found in topn= 100\n",
      "0 of 17 found in topn= 100\n",
      "0 of 28 found in topn= 100\n",
      "1 of 29 found in topn= 100\n",
      "1 of 38 found in topn= 100\n",
      "0 of 40 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 119 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 49 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "1 of 51 found in topn= 100\n",
      "0 of 47 found in topn= 100\n",
      "0 of 29 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 59 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 103 found in topn= 100\n",
      "0 of 48 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 62 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 20 found in topn= 100\n",
      "1 of 248 found in topn= 100\n",
      "1 of 17 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 37 found in topn= 100\n",
      "1 of 50 found in topn= 100\n",
      "1 of 42 found in topn= 100\n",
      "1 of 78 found in topn= 100\n",
      "0 of 29 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "1 of 147 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 22 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 40 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "1 of 38 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 66 found in topn= 100\n",
      "0 of 28 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "1 of 46 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 17 found in topn= 100\n",
      "0 of 36 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 113 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "1 of 40 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 41 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 36 found in topn= 100\n",
      "0 of 32 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 17 found in topn= 100\n",
      "0 of 22 found in topn= 100\n",
      "0 of 56 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 27 found in topn= 100\n",
      "0 of 44 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "1 of 24 found in topn= 100\n",
      "0 of 30 found in topn= 100\n",
      "0 of 20 found in topn= 100\n",
      "0 of 60 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 44 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 63 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 102 found in topn= 100\n",
      "1 of 106 found in topn= 100\n",
      "0 of 99 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 20 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 67 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 32 found in topn= 100\n",
      "0 of 46 found in topn= 100\n",
      "0 of 71 found in topn= 100\n",
      "0 of 31 found in topn= 100\n",
      "0 of 44 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 20 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 71 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 17 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 46 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 31 found in topn= 100\n",
      "0 of 17 found in topn= 100\n",
      "0 of 25 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 44 found in topn= 100\n",
      "0 of 37 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 55 found in topn= 100\n",
      "0 of 47 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "2 of 17 found in topn= 100\n",
      "0 of 20 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 53 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "1 of 11 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 140 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 30 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "2 of 27 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 31 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 41 found in topn= 100\n",
      "0 of 61 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 54 found in topn= 100\n",
      "0 of 44 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "1 of 16 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 39 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 33 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "0 of 37 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "2 of 26 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 46 found in topn= 100\n",
      "0 of 27 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "1 of 25 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 33 found in topn= 100\n",
      "0 of 22 found in topn= 100\n",
      "0 of 34 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "1 of 11 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 22 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 34 found in topn= 100\n",
      "0 of 26 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 25 found in topn= 100\n",
      "1 of 33 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 45 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "1 of 31 found in topn= 100\n",
      "1 of 12 found in topn= 100\n",
      "0 of 29 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 38 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "1 of 45 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 29 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 27 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 24 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "1 of 6 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 37 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 21 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 19 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 15 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 13 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 22 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 22 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "1 of 13 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 18 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 16 found in topn= 100\n",
      "0 of 14 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 11 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 23 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 10 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "1 of 4 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "1 of 6 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 9 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 12 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 7 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "1 of 8 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 8 found in topn= 100\n",
      "0 of 4 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 6 found in topn= 100\n",
      "0 of 3 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 5 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "0 of 2 found in topn= 100\n",
      "0 of 1 found in topn= 100\n",
      "Mean Percentage of good Recommendations (based on Test Split): 0.0034765208908240242\n"
     ]
    }
   ],
   "source": [
    "# Calculate Percentage of user rated movies from test split in recommended, top 10/50/100\n",
    "top_value = 100\n",
    "user_percentages = []\n",
    "userid_list_test = ratings_test['userId'].unique()\n",
    "for uid in userid_list_test:\n",
    "    if uid in all_user_profiles.keys():\n",
    "        user_profile = ratings_test.loc[ratings_test['userId'] == uid]\n",
    "        found_movies = 0\n",
    "        if uid in recommendation_users.keys():\n",
    "            user_recommendations = cleaned_recommendations[uid]\n",
    "            #print(len(user_recommendations))\n",
    "            #tmdbId_list = user_profile['tmdbId'].to_list():\n",
    "            user_profile_movie_list = user_profile['movieId'].to_list()\n",
    "            user_m_index_list = []\n",
    "            for m in user_profile_movie_list:\n",
    "                tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == m]\n",
    "                try:\n",
    "                    index = movieid_list.index(int(tmdbId))\n",
    "                    user_m_index_list.append(index)\n",
    "                except ValueError:\n",
    "                    #print(\"ValueError: \" + str(tmdbId))\n",
    "                    pass\n",
    "\n",
    "            for m_i, cos in user_recommendations[:top_value]:\n",
    "                try:\n",
    "                    if int(m_i) in user_m_index_list:\n",
    "                        found_movies = found_movies + 1\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            print(str(found_movies) + \" of \" + str(len(user_profile)) + \" found in topn= \" + str(top_value))\n",
    "\n",
    "        \n",
    "        #user_percentages.append(found_movies/top_value)\n",
    "        user_percentages.append(found_movies/len(user_profile))\n",
    "\n",
    "mean_percentage = sum(user_percentages)/len(user_percentages)\n",
    "print(\"Mean Percentage of good Recommendations (based on Test Split): \" + str(mean_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "99893     671      260     5.0  1064891246\n",
       "99973     671     4033     4.0  1065111954\n",
       "99992     671     5816     4.0  1065111963\n",
       "99930     671     1673     3.5  1063500961\n",
       "99954     671     2997     4.5  1063503848\n",
       "...       ...      ...     ...         ...\n",
       "99908     671     1035     5.0  1065149492\n",
       "99901     671      551     5.0  1063503908\n",
       "99997     671     5995     4.0  1066793014\n",
       "99919     671     1223     3.0  1064891236\n",
       "99976     671     4308     3.5  1065111985\n",
       "\n",
       "[80 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99893</th>\n      <td>671</td>\n      <td>260</td>\n      <td>5.0</td>\n      <td>1064891246</td>\n    </tr>\n    <tr>\n      <th>99973</th>\n      <td>671</td>\n      <td>4033</td>\n      <td>4.0</td>\n      <td>1065111954</td>\n    </tr>\n    <tr>\n      <th>99992</th>\n      <td>671</td>\n      <td>5816</td>\n      <td>4.0</td>\n      <td>1065111963</td>\n    </tr>\n    <tr>\n      <th>99930</th>\n      <td>671</td>\n      <td>1673</td>\n      <td>3.5</td>\n      <td>1063500961</td>\n    </tr>\n    <tr>\n      <th>99954</th>\n      <td>671</td>\n      <td>2997</td>\n      <td>4.5</td>\n      <td>1063503848</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99908</th>\n      <td>671</td>\n      <td>1035</td>\n      <td>5.0</td>\n      <td>1065149492</td>\n    </tr>\n    <tr>\n      <th>99901</th>\n      <td>671</td>\n      <td>551</td>\n      <td>5.0</td>\n      <td>1063503908</td>\n    </tr>\n    <tr>\n      <th>99997</th>\n      <td>671</td>\n      <td>5995</td>\n      <td>4.0</td>\n      <td>1066793014</td>\n    </tr>\n    <tr>\n      <th>99919</th>\n      <td>671</td>\n      <td>1223</td>\n      <td>3.0</td>\n      <td>1064891236</td>\n    </tr>\n    <tr>\n      <th>99976</th>\n      <td>671</td>\n      <td>4308</td>\n      <td>3.5</td>\n      <td>1065111985</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows  4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "user_profile = ratings_train.loc[ratings_train['userId'] == uid]\n",
    "#user_profile = ratings_train[ratings_train['userId'] == uid]\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    userId  movieId  rating   timestamp\n",
       "3        1     1129     2.0  1260759185\n",
       "16       1     2294     2.0  1260759108\n",
       "2        1     1061     3.0  1260759182\n",
       "17       1     2455     2.5  1260759113\n",
       "12       1     1953     4.0  1260759191\n",
       "11       1     1405     1.0  1260759203\n",
       "0        1       31     2.5  1260759144\n",
       "6        1     1287     2.0  1260759187\n",
       "14       1     2150     3.0  1260759194\n",
       "13       1     2105     4.0  1260759139\n",
       "8        1     1339     3.5  1260759125\n",
       "5        1     1263     2.0  1260759151\n",
       "4        1     1172     4.0  1260759205\n",
       "15       1     2193     2.0  1260759198\n",
       "1        1     1029     3.0  1260759179\n",
       "19       1     3671     3.0  1260759117\n",
       "10       1     1371     2.5  1260759135"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1129</td>\n      <td>2.0</td>\n      <td>1260759185</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1</td>\n      <td>2294</td>\n      <td>2.0</td>\n      <td>1260759108</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1061</td>\n      <td>3.0</td>\n      <td>1260759182</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>2455</td>\n      <td>2.5</td>\n      <td>1260759113</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>1953</td>\n      <td>4.0</td>\n      <td>1260759191</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>1405</td>\n      <td>1.0</td>\n      <td>1260759203</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>31</td>\n      <td>2.5</td>\n      <td>1260759144</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1287</td>\n      <td>2.0</td>\n      <td>1260759187</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>2150</td>\n      <td>3.0</td>\n      <td>1260759194</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>2105</td>\n      <td>4.0</td>\n      <td>1260759139</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1339</td>\n      <td>3.5</td>\n      <td>1260759125</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>1263</td>\n      <td>2.0</td>\n      <td>1260759151</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1172</td>\n      <td>4.0</td>\n      <td>1260759205</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>2193</td>\n      <td>2.0</td>\n      <td>1260759198</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1029</td>\n      <td>3.0</td>\n      <td>1260759179</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>3671</td>\n      <td>3.0</td>\n      <td>1260759117</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>1371</td>\n      <td>2.5</td>\n      <td>1260759135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "u_p = ratings_train.loc[ratings_train['userId'] == 1]\n",
    "print(len(u_p))\n",
    "u_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile_movie_list = u_p['movieId'].to_list()\n",
    "user_m_index_list = []\n",
    "tmdbId_list = []\n",
    "for m in user_profile_movie_list:\n",
    "    tmdbId = links_small['tmdbId'].loc[links_small['movieId'] == m]\n",
    "    try:\n",
    "        index = movieid_list.index(int(tmdbId))\n",
    "        user_m_index_list.append(index)\n",
    "        tmdbId_list.append(int(tmdbId))\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1094,\n",
       " 2181,\n",
       " 1031,\n",
       " 2342,\n",
       " 1844,\n",
       " 1354,\n",
       " 30,\n",
       " 1242,\n",
       " 2041,\n",
       " 1996,\n",
       " 1291,\n",
       " 1218,\n",
       " 1132,\n",
       " 2084,\n",
       " 1000,\n",
       " 3549,\n",
       " 1322]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "user_m_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.03232411  0.06542593 -0.11860172 -0.02738422  0.08786373 -0.22847934\n  0.04131952  0.31932786  0.1022366   0.07084516 -0.36353967 -0.15571275\n  0.02770765  0.00269941 -0.27729848 -0.03791951  0.0838308  -0.12735762\n -0.06881724 -0.17752264  0.12573136 -0.15369149  0.32569042  0.26659033\n -0.05534959  0.01232429  0.15964577  0.03472032 -0.4914102   0.0380314\n  0.04588491  0.07267144 -0.2519488  -0.05532525 -0.28103018 -0.00348903\n  0.02023853  0.14145832  0.05940605 -0.01254564 -0.00198155 -0.01974271\n  0.22153623  0.10047508  0.4180624   0.17659213  0.11772286 -0.24227077\n  0.13943994  0.02141049]\n['Toy', 'Story', '2', 'Andy', 'heads', 'off', 'to', 'Cowboy', 'Camp,', 'leaving', 'his', 'toys', 'to', 'their', 'own', 'devices.', 'Things', 'shift', 'into', 'high', 'gear', 'when', 'an', 'obsessive', 'toy', 'collector', 'named', 'Al', 'McWhiggen,', 'owner', 'of', \"Al's\", 'Toy', 'Barn', 'kidnaps', 'Woody.', \"Andy's\", 'toys', 'mount', 'a', 'daring', 'rescue', 'mission,', 'Buzz', 'Lightyear', 'meets', 'his', 'match', 'and', 'Woody', 'has', 'to', 'decide', 'where', 'he', 'and', 'his', 'heart', 'truly', 'belong.']\n"
     ]
    }
   ],
   "source": [
    "#inferred_vector = model.infer_vector(tagged_text[1585].words)\n",
    "\n",
    "#inferred_vector = model.infer_vector(text)\n",
    "print(inferred_vector)\n",
    "print(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id                title  \\\n",
       "540  954  Mission: Impossible   \n",
       "\n",
       "                                              overview  \n",
       "540  When Ethan Hunt, the leader of a crack espiona...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>overview</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>540</th>\n      <td>954</td>\n      <td>Mission: Impossible</td>\n      <td>When Ethan Hunt, the leader of a crack espiona...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "test = df[df['title'] == 'Mission: Impossible']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(208, 1.0000001192092896), (988, 0.9461885094642639), (4939, 0.9310348033905029), (977, 0.9279372096061707), (37292, 0.9215072393417358), (33017, 0.9209285974502563), (15498, 0.9153652787208557), (34522, 0.9128983020782471), (22571, 0.9114615321159363), (9695, 0.9062817096710205)]\nStar Wars\nReturn of the Jedi\nThe Sword and the Sorcerer\nThe Empire Strikes Back\nGor\nKingsglaive: Final Fantasy XV\nAsterix and the Vikings\nRogue One: A Star Wars Story\nStar Wars: The Force Awakens\nThe Conqueror\n\n[(208, 0.9564753174781799), (977, 0.8945705890655518), (988, 0.8773837089538574), (33017, 0.8724589347839355), (22571, 0.8557488918304443), (4939, 0.8529732823371887), (34522, 0.840722382068634), (37292, 0.8355525135993958), (15498, 0.8342955112457275), (25769, 0.8294712901115417), (9695, 0.8277966380119324), (7752, 0.8274527192115784), (2161, 0.8174904584884644), (26458, 0.8165868520736694), (15188, 0.8074105978012085), (17113, 0.8060462474822998), (5792, 0.8058078289031982), (11597, 0.8056795597076416), (17705, 0.8053046464920044), (13028, 0.8051697015762329)]\nStar Wars\nThe Empire Strikes Back\nReturn of the Jedi\nKingsglaive: Final Fantasy XV\nStar Wars: The Force Awakens\nThe Sword and the Sorcerer\nRogue One: A Star Wars Story\nGor\nAsterix and the Vikings\nThe Star Wars Holiday Special\nThe Conqueror\nBarbarian Queen II: The Empress Strikes Back\nStar Wars: Episode I - The Phantom Menace\nSonic The Hedgehog: The Movie\nWarrior of the Lost World\nHarem suare\nThe Magic Sword\nFlash Gordon\nThe Invincible Iron Man\nPrince of Persia: The Sands of Time\n"
     ]
    }
   ],
   "source": [
    "vec_u = model.dv[208]\n",
    "#print(vec)\n",
    "sim = model.dv.most_similar([vec_u],topn=10)\n",
    "\n",
    "inferred_vector = model.infer_vector(tagged_text[208].words, steps=30, alpha=0.025)\n",
    "sim3 = model.dv.most_similar([inferred_vector], topn=20)\n",
    "\n",
    "print(sim)\n",
    "indexes =[i[0] for i in sim]\n",
    "for i in indexes:\n",
    "    print(df['title'][i])\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(sim3)\n",
    "indexes =[i[0] for i in sim3]\n",
    "for i in indexes:\n",
    "    print(df['title'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.942365]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "cosine_similarity(inferred_vector.reshape(1, -1),vec_u.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cos Sim: \n[[1.         0.42783525 0.36287829 0.30135735]\n [0.42783525 1.         0.42588261 0.54596214]\n [0.36287829 0.42588261 1.         0.55471191]\n [0.30135735 0.54596214 0.55471191 1.        ]]\nBatman\nWonder Woman\nDetective Byomkesh Bakshy!\nLawnmower Man 2: Beyond Cyberspace\nFreaky Deaky\nLink\nCaptain Video, Master of the Stratosphere\nSmall Soldiers\nGet Smart, Again!\nSuperman vs. The Elite\nMid: 0\nRank: 5074\nMid: 4460\nRank: 55\nMid: 15159\nRank: 16\nMid: 497\nRank: 196\nMax Rank = 37713\nAverage Rank of already seen movies: 1335.25\n"
     ]
    }
   ],
   "source": [
    "# Toy Story, Spider-Man, The Avengers, Batman\n",
    "mids = [0,4460,15159,497]\n",
    "inferred_vector1 = model.infer_vector(tagged_text[0].words, steps=30, alpha=0.025)\n",
    "inferred_vector2 = model.infer_vector(tagged_text[4460].words, steps=30, alpha=0.025)\n",
    "inferred_vector3 = model.infer_vector(tagged_text[15159].words, steps=30, alpha=0.025)\n",
    "inferred_vector4 = model.infer_vector(tagged_text[497].words, steps=30, alpha=0.025)\n",
    "\n",
    "\n",
    "test_user_array = np.zeros((4,len(inferred_vector1)))\n",
    "test_user_array[0] = inferred_vector1\n",
    "test_user_array[1] = inferred_vector2\n",
    "test_user_array[2] = inferred_vector3\n",
    "test_user_array[3] = inferred_vector4\n",
    "\n",
    "cos_sim = cosine_similarity(test_user_array, test_user_array)\n",
    "print(\"Cos Sim: \")\n",
    "print(cos_sim)\n",
    "\n",
    "test_user = np.mean(test_user_array, axis=0)\n",
    "\n",
    "sim = model.dv.most_similar([test_user], topn=len(model.dv))\n",
    "\n",
    "#print(sim)\n",
    "indexes =[i[0] for i in sim[:10]]\n",
    "for i in indexes:\n",
    "    print(df['title'][i])\n",
    "\n",
    "#rank\n",
    "rank_list = []\n",
    "for mid in mids:\n",
    "    rank = 0\n",
    "    print(\"Mid: \" + str(mid))\n",
    "    for m_i, cos in sim:\n",
    "        if m_i == mid:\n",
    "            print(\"Rank: \" + str(rank))\n",
    "            break\n",
    "        rank = rank + 1\n",
    "        \n",
    "    rank_list.append(rank)   \n",
    "\n",
    "print(\"Max Rank = \" + str(len(df)))\n",
    "average_rank = sum(rank_list) / len(rank_list)\n",
    "print(\"Average Rank of already seen movies: \" + str(average_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[20, 14, 20, 20]"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ],
   "source": [
    "rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cos Sim: \n[[1.         0.29128387 0.47421021 0.28500423]\n [0.29128387 1.         0.39641955 0.44367252]\n [0.47421021 0.39641955 1.         0.46195455]\n [0.28500423 0.44367252 0.46195455 1.        ]]\n[(16829, 0.8986981511116028), (14813, 0.8905784487724304), (33350, 0.8882643580436707), (19358, 0.8848171830177307), (8604, 0.88371741771698), (6612, 0.8831021189689636), (9444, 0.8820332884788513), (3819, 0.8818320035934448), (20618, 0.877967119216919), (23359, 0.8763169050216675)]\nFate of a Man\nCornered\nChosen\nHornet's Nest\nAct of Violence\nThree Came Home\nTrial on the Road\nCasualties of War\nThe Look of Silence\nThe Diary of Anne Frank\nMid: 0\nRank: 36009\nMid: 4460\nRank: 27256\nMid: 15159\nRank: 14797\nMid: 497\nRank: 8926\nMax Rank = 37713\nAverage Rank of already seen movies: 21747.0\n"
     ]
    }
   ],
   "source": [
    "# The Godfather, The Bourne Identity, The Pianist, Saving Pravite Rayn\n",
    "inferred_vector1 = model.infer_vector(tagged_text[694].words, steps=30, alpha=0.025)\n",
    "inferred_vector2 = model.infer_vector(tagged_text[4523].words, steps=30, alpha=0.025)\n",
    "inferred_vector3 = model.infer_vector(tagged_text[5018].words, steps=30, alpha=0.025)\n",
    "inferred_vector4 = model.infer_vector(tagged_text[1637].words, steps=30, alpha=0.025)\n",
    "\n",
    "\n",
    "test_user_array = np.zeros((4,len(inferred_vector1)))\n",
    "test_user_array[0] = inferred_vector1\n",
    "test_user_array[1] = inferred_vector2\n",
    "test_user_array[2] = inferred_vector3\n",
    "test_user_array[3] = inferred_vector4\n",
    "\n",
    "cos_sim = cosine_similarity(test_user_array, test_user_array)\n",
    "print(\"Cos Sim: \")\n",
    "print(cos_sim)\n",
    "\n",
    "test_user = np.mean(test_user_array, axis=0)\n",
    "\n",
    "sim = model.dv.most_similar([test_user], topn=len(model.dv))\n",
    "\n",
    "print(sim[:10])\n",
    "indexes =[i[0] for i in sim[:10]]\n",
    "for i in indexes:\n",
    "    print(df['title'][i])\n",
    "\n",
    "#rank\n",
    "rank_list = []\n",
    "for mid in mids:\n",
    "    rank = 0\n",
    "    print(\"Mid: \" + str(mid))\n",
    "    for m_i, cos in sim:\n",
    "        if m_i == mid:\n",
    "            print(\"Rank: \" + str(rank))\n",
    "            break\n",
    "        rank = rank + 1\n",
    "        \n",
    "    rank_list.append(rank)   \n",
    "\n",
    "print(\"Max Rank = \" + str(len(df)))\n",
    "average_rank = sum(rank_list) / len(rank_list)\n",
    "print(\"Average Rank of already seen movies: \" + str(average_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({0: 40457, 1: 934, -1: 732, 2: 404, 3: 244, 4: 180, 5: 142, 6: 94, 7: 71, 8: 66, 9: 57, 13: 56, 10: 50, 11: 49, 16: 49, 12: 44, 14: 42, 17: 36, 19: 32, 20: 29, 15: 27, 21: 26, 18: 25, 26: 23, 24: 22, 25: 22, 23: 22, 31: 18, 22: 17, 38: 17, 28: 17, 27: 16, 30: 16, 29: 15, 39: 14, 42: 14, 59: 13, 33: 13, 54: 13, 35: 13, 36: 12, 37: 12, 34: 12, 48: 11, 51: 10, 55: 10, 32: 9, 49: 9, 44: 9, 84: 9, 63: 9, 43: 9, 56: 8, 40: 8, 41: 8, 57: 8, 81: 8, 85: 8, 50: 7, 69: 7, 46: 7, 58: 7, 91: 7, 47: 7, 72: 7, 53: 7, 92: 7, 66: 7, 73: 6, 78: 6, 64: 6, 52: 6, 45: 6, 83: 6, 60: 5, 77: 5, 96: 5, 70: 5, 71: 5, 82: 5, 95: 5, 65: 4, 67: 4, 98: 4, 80: 4, 68: 4, 76: 4, 61: 4, 79: 4, 97: 4, 87: 3, 93: 3, 90: 3, 74: 2, 89: 2, 88: 2, 99: 2, 75: 2, 86: 2, 62: 2, 94: 1})\n0.9091256376261208\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "for t in range(len(tagged_text)):\n",
    "    inferred_vector = model.infer_vector(tagged_text[t].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=100)\n",
    "    try:\n",
    "        rank = [docid for docid, sim in sims].index(t)\n",
    "        ranks.append(rank)\n",
    "    except ValueError:\n",
    "        ranks.append(-1)\n",
    "\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)\n",
    "print(counter[0]/len(tagged_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     id      title                                           overview\n",
       "208  11  Star Wars  Princess Leia is captured and held hostage by ..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>overview</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>208</th>\n      <td>11</td>\n      <td>Star Wars</td>\n      <td>Princess Leia is captured and held hostage by ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "s = df[df['title'] == 'Star Wars']\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only cos, sorted by index for model input\n",
    "rec = recommendation_users\n",
    "for k,l in rec.items():\n",
    "    l.sort(key=lambda x:x[0])\n",
    "    rec[k] = l\n",
    "\n",
    "cos_inputs = {}\n",
    "for uid in userid_list:\n",
    "    u_reco = rec[uid]\n",
    "    u_reco_list = list(map(list, zip(*u_reco)))\n",
    "    u_reco_cos_array = np.array(u_reco_list[1])\n",
    "    cos_inputs[uid] = u_reco_cos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "44501"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "len(cos_inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.32758981, 0.42638624, 0.49069268, 0.64956218, 0.2503736 ,\n",
       "       0.69869506, 0.49557298, 0.47686332, 0.31756526, 0.59661818])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "cos_inputs[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('doc2vec_vecsize_50_cos_inputs.pickle', 'wb') as f:\n",
    "    pickle.dump(all_user_bitarrays,f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}